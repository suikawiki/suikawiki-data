head	1.3;
access;
symbols
	before-db-leaffile:1.2
	after-upgrade-to-suikawiki-3:1.2
	before-fork-suikawiki3:1.2
	after-restore-20040122:1.2;
locks; strict;
comment	@# @;


1.3
date	2004.12.08.02.07.04;	author wakaba;	state dead;
branches;
next	1.2;

1.2
date	2002.10.21.13.24.47;	author wakaba;	state Exp;
branches;
next	1.1;

1.1
date	2002.07.29.12.01.58;	author wakaba;	state Exp;
branches;
next	;


desc
@@


1.3
log
@auto-committed
@
text
@#?SuikaWiki/0.9
*4.3.4.2 Content-Disposition:

>This field MUST be present to allow the parsable identification of
these body parts.  This is especially useful if, as is typical, more
than one Audio/32KADPCM body occurs within a single level (e.g.
multipart/voice-message).  Since a VPIM voice message is intended to
be automatically played upon display of the message, in the order in
which the audio contents occur, the audio contents must always be of
type inline.  However, it is still useful to include a filename
value, so this should be present if this information is available.
From [DISP]

   In order to distinguish between the various types of audio contents
   in a VPIM voice message a new disposition parameter "voice" is
   defined with the parameter values below to be used as appropriate
   (see 18.2):

     Voice-Message - the primary voice message,
     Voice-Message-Notification - a spoken delivery notification
       or spoken disposition notification,
     Originator-Spoken-Name - the spoken name of the originator,
     Recipient-Spoken-Name - the spoken name of the recipient if
       available to the originator and present if there is ONLY one
       recipient,
     Spoken-Subject- the spoken subject of the message, typically
       spoken by the originator

   Note that there SHOULD only be one instance of each of these types of
   audio contents per message level.  Additional instances of a given
   type (i.e., parameter value) may occur within an attached forwarded
   voice message.

   Implementations that do not understand the "voice" parameter (or the
   Content-Disposition header) can safely ignore it, and will present
   the audio bodyparts in order (but will not be able to distinguish
   between them).

   Example:

       Content-Disposition: inline; voice=spoken-subject;
                           filename="msg001.726"

*18.2 Voice Content-Disposition Parameter Definition

   To: IANA@@IANA.ORG

   Subject: Registration of new Content-Disposition parameter


   Content-Disposition parameter name: voice

   Allowable values for this parameter:

          Voice-Message - the primary voice message,
          Voice-Message-Notification - a spoken delivery notification
            or spoken disposition notification,
          Originator-Spoken-Name - the spoken name of the originator,
          Recipient-Spoken-Name - the spoken name of the recipient if
            available to the originator and present if there is ONLY one
            recipient,
          Spoken-Subject- the spoken subject of the message, typically
            spoken by the originator

   Description:

   In order to distinguish between the various types of audio contents
   in a VPIM voice message a new disposition parameter "voice" is
   defined with the preceding values to be used as appropriate. Note
   that there SHOULD only be one instance of each of these types of
   audio contents per message level.  Additional instances of a given
   type (i.e., parameter value) may occur within an attached forwarded
   voice message.

*RFC の部分の LICENSE

See [[RFCのライセンス]]

*メモ
@


1.2
log
@Updated.
@
text
@@


1.1
log
@Updated.
@
text
@d1 2
a2 1
*****4.3.4.2 Content-Disposition:
d4 9
a12 9
   This field MUST be present to allow the parsable identification of
   these body parts.  This is especially useful if, as is typical, more
   than one Audio/32KADPCM body occurs within a single level (e.g.
   multipart/voice-message).  Since a VPIM voice message is intended to
   be automatically played upon display of the message, in the order in
   which the audio contents occur, the audio contents must always be of
   type inline.  However, it is still useful to include a filename
   value, so this should be present if this information is available.
   From [DISP]
d44 1
a44 1
***18.2 Voice Content-Disposition Parameter Definition
d75 1
a75 8
*SEE ALSO

-[[RFC822]]
-[[MIME]]
--[[Content-Type:領域]]
--[[Content-Disposition:領域]]

*LICENSE
d79 1
a79 1

@

