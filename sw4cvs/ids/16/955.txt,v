head	1.1;
access;
symbols;
locks; strict;
comment	@# @;
expand	@b@;


1.1
date	2011.01.08.12.22.47;	author wakaba;	state Exp;
branches;
next	;


desc
@@


1.1
log
@created by (anon)
@
text
@Ant Colony System:
A Cooperative Learning Approach to the
Traveling Salesman Problem
{{category Ant Colony System}}
{{category ACS}}

{{paper ant/dorigo96ant-1.pdf}}

TR/IRIDIA/1996-5

Université Libre de Bruxelles
Belgium

Marco Dorigo
{{category Marco Dorigo}}
{{category M. Dorigo}}

IRIDIA, Université Libre de Bruxelles, CP 194/6, Avenue Franklin Roosevelt 50
1050 Bruxelles, Belgium
mdorigo@@ulb.ac.be, http://iridia.ulb.ac.be/dorigo/dorigo.html

Luca Maria Gambardella
{{category Luca Maria Gambardella}}
{{category L. M. Gambardella}}

IDSIA, Corso Elvezia 36, 6900 Lugano, Switzerland
luca@@idsia.ch, http://www.idsia.ch/~luca

*Abstract

This paper introduces ant colony system (ACS), a distributed algorithm that is applied to
the traveling salesman problem (TSP). In ACS, a set of cooperating agents called ants
cooperate to find good solutions to TSPs. Ants cooperate using an indirect form of
communication mediated by pheromone they deposit on the edges of the TSP graph while
building solutions. We study ACS by running experiments to understand its operation.
The results show that ACS outperforms other nature-inspired algorithms such as simulated
annealing and evolutionary computation, and we conclude comparing ACS-3-opt, a version
of ACS augmented with a local search procedure, to some of the best performing
algorithms for symmetric and asymmetric TSPs.

{{category ACO}}

Accepted for publication in the IEEE Transactions on Evolutionary Computation, Vol.1, No.1, 1997. In press.
{{category 1997}}

* Ant System の問題点

Although ant system was useful for discovering good or optimal solutions for small TSPs (up
to 30 cities), the time required to find such results made it unfeasible for larger problems. We
devised three main changes to improve its performance which led to the definition of ACS,
presented in the next section.

* Ant System との差異

ACS differs from the previous ant system because of three main aspects: (i) the state transition
rule provides a direct way to balance between exploration of new edges and exploitation of a
priori and accumulated knowledge about the problem, (ii) the global updating rule is applied
only to edges which belong to the best ant tour, and (iii) while ants construct a solution a local
pheromone updating rule (local updating rule, for short) is applied.

^ 状態遷移則 = pseudo-random-proportional rule: 新経路の探索とフェロモン従属を直接調節 {{category pseudo-random-proportional rule}}
- global updating rule は best tour のみ適用 {{category global updating rule}}
- local updating rule {{category local updating rule}}

** 状態遷移則

- 確率 q_0 (パラメータ) で、一番確率が高い経路を選択
- 1-q_0 で、従来通りの確率に従い経路を選択

** global updating rule

best tour のみ

τ(r,s) ← (1-α)τ(r,s) + α Δτ(r,s)

Δτ(r,s) = L_gb ^-1 (best tour を構成する辺) or 0 (otherwise)

L_gb は best tour の長さ

!! local updating rule

τ(r,s) ← (1-α)τ(r,s) + α Δτ(r,s)

Δτの決め方として3通り試した:
- [[Ant-Q]]: [[Q-learning]] に倣い、 Δτ(r,s) = γ max_{z in J_k(s)} τ(s,z)
- [[ACS]]: Δτ(r,s) = τ_0 (フェロモン初期値)
- Δτ(r,s) = 0

結果、 local update なしよりは Δτ=0、
Δτ=0 よりは Ant-Q や ACS の方が良かった。

Ant-Q と ACS の良さは同程度だった。

the role of ACS local updating rule is to shuffle the
tours, so that the early cities in one ant’s tour may be explored later in other ants’ tours. In other
words, the effect of local-updating is to make the desirability of edges change dynamically:
every time an ant uses an edge this becomes slightly less desirable (since it loses some of its
pheromone). In this way ants will make a better use of pheromone information: without localupdating
all ants would search in a narrow neighborhood of the best previous tour.

*References

+[1] S. Baluja and R. Caruana, “Removing the genetics from the standard genetic algorithm,” Proceedings of ML-95, Twelfth International Conference on Machine Learning, A. Prieditis and S. Russell (Eds.), 1995, Morgan Kaufmann, pp. 38&#8211;46.
+[2] A.G. Barto, R.S. Sutton, P.S. Brower, “[[Associative search network: a reinforcement learning associative memory|Associative search network a reinforcement learning associative memory]],” Biological Cybernetics, vol. 40, pp. 201&#8211;211, 1981.
+[3] R. Beckers, J.L. Deneubourg, and S. Goss, “Trails and U-turns in the selection of the shortest path by the ant Lasius Niger,” Journal of Theoretical Biology, vol. 159, pp. 397&#8211;415, 1992.
+[4] J.L. Bentley, “Fast algorithms for geometric traveling salesman problems,” ORSA Journal on Computing, vol. 4, pp. 387&#8211;411, 1992.
+[5] H. Bersini, M. Dorigo, S. Langerman, G. Seront, and L. M. Gambardella, “[[Results of the first international contest on evolutionary optimisation (1st ICEO)]],” Proceedings of IEEE International Conference on Evolutionary Computation, IEEE-EC 96, 1996, IEEE Press, pp. 611&#8211;615.
+[6] H. Bersini, C. Oury, and M. Dorigo, “[[Hybridization of genetic algorithms]],” Tech. Rep. No. IRIDIA/95-22, 1995, Université Libre de Bruxelles, Belgium.
+[7] A. Colorni, M. Dorigo, and V. Maniezzo, “[[Distributed optimization by ant colonies]],” Proceedings of ECAL91 - European Conference on Artificial Life, Paris, France, 1991, F. Varela and P. Bourgine (Eds.), Elsevier Publishing, pp. 134&#8211;142.
+[8] A. Colorni, M. Dorigo, and V. Maniezzo, “[[An investigation of some properties of an ant algorithm]],” Proceedings of the Parallel Problem Solving from Nature Conference (PPSN 92), 1992, R. Männer and B. Manderick (Eds.), Elsevier Publishing, pp. 509&#8211;520.
+[9] J.L. Deneubourg, “[[Application de l’ordre par fluctuations à la description de certaines étapes de la construction du nid chez les termites]],” Insect Sociaux, vol. 24, pp. 117&#8211;130, 1977.
+[10] M. Dorigo, [[Optimization, learning and natural algorithms]]. Ph.D.Thesis, DEI, Politecnico di Milano, Italy, 1992. (In Italian.)
+[11] M. Dorigo and L.M. Gambardella, “[[A study of some properties of Ant-Q]],” Proceedings of PPSN IV&#8211;Fourth International Conference on Parallel Problem Solving From Nature, H.&#8211;M. Voigt, W. Ebeling, I. Rechenberg and H.&#8211;S. Schwefel (Eds.), Springer-Verlag, Berlin, 1996, pp. 656&#8211;665.
+[12] M. Dorigo, V. Maniezzo, and A.Colorni, “[[The ant system: optimization by a colony of cooperating agents|The ant system: optimization by a colony of cooperating agents]],” IEEE Transactions on Systems, Man, and Cybernetics&#8211;Part B, vol. 26, No. 2, pp. 29&#8211;41, 1996.
+[13] R. Durbin and D. Willshaw, “An analogue approach to the travelling salesman problem using an elastic net method,” Nature, vol. 326, pp. 689-691, 1987.
+[14] S. Eilon, C.D.T. Watson-Gandy, and N. Christofides, “[[Distribution management: mathematical modeling and practical analysis|Distribution management mathematical modeling and practical analysis]],” Operational Research Quarterly, vol. 20, pp. 37&#8211;53, 1969.
+[15] D. Fogel, “Applying evolutionary programming to selected traveling salesman problems,” Cybernetics and Systems: An International Journal, vol. 24, pp. 27&#8211;36, 1993.
+[16] M.L. Fredman, D.S. Johnson, L.A. McGeoch, and G. Ostheimer, “Data structures for traveling salesmen,” Journal of Algorithms, vol. 18, pp. 432&#8211;479, 1995.
[17] B. Freisleben and P. Merz, “Genetic local search algorithm for solving symmetric and asymmetric
traveling salesman problems,” Proceedings of IEEE International Conference on Evolutionary
Computation, IEEE-EC 96, 1996, IEEE Press, pp. 616-621.
[18] B. Freisleben and P. Merz, “New genetic local search operators for the traveling salesman
problem,” Proceedings of PPSN IV&#8211;Fourth International Conference on Parallel Problem Solving
From Nature, H.&#8211;M. Voigt, W. Ebeling, I. Rechenberg and H.&#8211;S. Schwefel (Eds.), Springer-
Verlag, Berlin, 1996, pp. 890&#8211;899.
+[19] L. M. Gambardella and M. Dorigo, “[[Ant-Q: a reinforcement learning approach to the traveling salesman problem|Ant-Q a reinforcement learning approach to the traveling salesman problem]],” Proceedings of ML-95, Twelfth International Conference on Machine Learning, A. Prieditis and S. Russell (Eds.), Morgan Kaufmann, 1995, pp. 252&#8211;260.
+[20] L.M. Gambardella and M. Dorigo, “[[Solving symmetric and asymmetric TSPs by ant colonies]],” Proceedings of IEEE International Conference on Evolutionary Computation, IEEE-EC 96, IEEE Press, 1996, pp. 622&#8211;627.
[21] B. Golden and W. Stewart, “Empiric analysis of heuristics,” in The traveling salesman problem,
E.L. Lawler, J.K. Lenstra, A.H.G. Rinnooy-Kan, D.B. Shmoys (Eds.), New York: Wiley and Sons,
1985.
+[22] S. Goss, S. Aron, J.L. Deneubourg, and J.M. Pasteels, “Self-organized shortcuts in the argentine ant,” Naturwissenschaften, vol. 76, pp. 579&#8211;581, 1989.
[23] P. P. Grassé, “La reconstruction du nid et les coordinations inter-individuelles chez Bellicositermes
natalensis et Cubitermes sp. La théorie de la stigmergie: Essai d’interprétation des termites
constructeurs,” Insect Sociaux, vol. 6, pp. 41&#8211;83, 1959.
[24] B. Hölldobler and E.O. Wilson, The ants. Springer-Verlag, Berlin, 1990.
[25] D.S. Johnson and L.A. McGeoch, “The travelling salesman problem: a case study in local
optimization,” in Local Search in Combinatorial Optimization, E.H.L. Aarts and J.K. Lenstra
(Eds.), New York: Wiley and Sons, 1997.
[26] L.P. Kaelbling, L.M. Littman and A.W. Moore, “Reinforcement learning: a survey,” Journal of
Artificial Intelligence Research, vol. 4, pp. 237&#8211;285, 1996.
[27] P-C. Kanellakis and C.H. Papadimitriou, “Local search for the asymmetric traveling salesman
problem,” Operations Research, vol. 28, no. 5, pp. 1087&#8211;1099, 1980.
[28] E. L. Lawler, J. K. Lenstra, A. H. G. Rinnooy-Kan, and D. B. Shmoys (Eds.), The traveling
salesman problem. New York: Wiley and Sons, 1985.
[29] F.&#8211;T. Lin, C.&#8211;Y. Kao, and C.&#8211;C. Hsu, “Applying the genetic approach to simulated annealing in
solving some NP-Hard problems,” IEEE Transactions on Systems, Man, and Cybernetics, vol. 23,
pp. 1752&#8211;1767, 1993.
[30] S. Lin., “Computer solutions of the traveling salesman problem,” Bell Systems Journal, vol. 44, pp.
2245&#8211;2269, 1965.
[31] S. Lin and B.W. Kernighan, “An effective heuristic algorithm for the traveling salesman problem,”
Operations Research, vol. 21, pp. 498&#8211;516, 1973.
+[32] V. Maniezzo, A.Colorni, and M.Dorigo, “The ant system applied to the quadratic assignment problem,” Tech. Rep. IRIDIA/94-28, 1994, Université Libre de Bruxelles, Belgium.
[33] O. Martin, S.W. Otto, and E.W. Felten, “Large-step Markov chains for the TSP incorporating local
search heuristics,” Operations Research Letters, vol. 11, pp. 219-224, 1992.
[34] J.&#8211;Y. Potvin, 1993, “The traveling salesman problem: a neural network perspective,” ORSA Journal
of Computing, vol. 5, No. 4, pp. 328&#8211;347.
[35] G. Reinelt, The traveling salesman: computational solutions for TSP applications. Springer-Verlag,
1994.
[36] D.J. Rosenkrantz, R.E. Stearns, and P.M. Lewis, “An analysis of several heuristics for the traveling
salesman problem,” SIAM Journal on Computing, vol. 6, pp. 563&#8211;581, 1977.
[37] R. Schoonderwoerd, O. Holland, J. Bruten, and L. Rothkrantz, “Ant-based load balancing in
telecommunications networks,” Adaptive Behavior, vol.5, No.2, 1996.
+[38] T. Stützle and H. Hoosa, “[[Improvements on the ant system, introducing the MAX-MIN ant system]],” Proceedings of ICANNGA97 - Third International Conference on Artificial Neural Networks and Genetic Algorithms, 1997, University of East Anglia, Norwich, UK.
+[39] T. Stützle and H. Hoos, “[[The ant system and local search for the traveling salesman problem]],” Proceedings of ICEC'97 - 1997 IEEE 4th International Conference on Evolutionary Computation, 1997, IEEE Press.
[40] C.J.C.H. Watkins, Learning with delayed rewards. Ph.D. dissertation, Psychology Department,
University of Cambridge, England, 1989.
[41] D. Whitley, T. Starkweather, and D. Fuquay, “Scheduling problems and travelling salesman: the genetic
edge recombination operator,” Proceedings of the Third International Conference on Genetic
Algorithms, Morgan Kaufmann, 1989, pp. 133&#8211;140.
+[42] L. M. Gambardella, E. Taillard, and M. Dorigo, "[[Ant Colonies for QAP]]," IDSIA, Lugano, Switzerland, Tech. Rep. IDSIA 97-4, 1997.

@
