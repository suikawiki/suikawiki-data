head	1.1;
access;
symbols;
locks; strict;
comment	@# @;
expand	@b@;


1.1
date	2011.01.08.12.52.51;	author wakaba;	state Exp;
branches;
next	;


desc
@@


1.1
log
@created by (anon)
@
text
@Latent Learning in Agents

{{paper learning/LatentLearningiCML.pdf}}

Rati Sharma
{{category Rati Sharma}}
{{category R. Sharma}}

*Abstract   

Various cognitive models have been proposed to
determine optimal paths in spatial navigation
tasks, some of which demonstrate latent learning
in Agents. We view and present the model as a
Reinforcement Learning problem by using QLearning
and Model-Based Learning in a
deterministic environment. This paper uses a QLearning
algorithm and compares its
performance with the Dyna (Model based)
algorithm on Blocking and Shortcut problems.
We conclude that using Model-Based
Reinforcement learning provides an interesting
and efficient solution to blocking and shortcut
problems and that the agent demonstrates Latent
Learning.
{{category Q-learning}}
{{category Dyna}}

*要旨

Q-learning と Dyna (Dyna-Q?) の比較。
Dyna は shortcut problem 的にも良い。
{{category shortcut problem}}

*References 

+Kaelbling, L., Littman, M., Moore, A. (1996) [[Reinforcement Learning: A survey]]. Journal of Artificial Intelligence Research, 4, 237-285. 
+Sutton, R. (1990) [[Integrated Architectures for Learning, Planning and Reacting based on Approximate Dynamic Programming]]. Appeared in Proceedings of the Seventh International Conference on Machine Learning, pp. 216-224, Morgan Kaufmann. 
+Tolman, E.C. (1948). [[Cognitive maps in Rats and Men]]. The Psychological Review. 55(4), 189-208
+Voicu, H., Schmajuk, N. (2002). [[Latent Learning, shortcuts and detours: a computational model|Latent Learning, shortcuts and detours a computational model]]. Behavioral Processes 59 (2002) 67-86.



@
