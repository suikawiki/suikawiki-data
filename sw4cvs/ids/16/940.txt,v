head	1.1;
access;
symbols;
locks; strict;
comment	@# @;
expand	@b@;


1.1
date	2011.01.08.12.05.37;	author wakaba;	state Exp;
branches;
next	;


desc
@@


1.1
log
@created by (anon)
@
text
@Accelerated Ants Routing in Dynamic Networks

{{paper ant/SNPD01-2.pdf}}

Hiroshi Matsuo, Kouichi Mori
{{category Hiroshi Matsuo}}
{{category Kouichi Mori}}

Nagoya Institute of Technology, Gokiso, Nagoya, 466-8555, JAPAN
matsuo@@elcom.nitech.ac.jp

*Abstract

Efficiently routing in a dynamic network is a important
problem in ad hoc network according to development of personal
data assistant (PDA) and wireless network equipment.
However conventional routing algorithm is difficult to apply
to dynamic topology network. Q-Routing, DRQ-Routing
and Ants-Routing which are based on reinforcement learning
technique are proposed. But convergence speed and routing
result are still unsatisfied. In this paper, accelerated Ants-
Routing which increase convergence speed and obtain good
routing path is discussed. Experiment on dynamic network
showed that accelerated Ants-Routing learns the optimum
routing in terms of convergence speed and average packet
latency.

{{category Ant Routing}}
{{category MANET}}

{{category 確率更新}}
{{category 増加:重み付き}}
{{category 蒸発:正規化}}

{{category ABC}}
{{category Ants-Routing}} [5]

*References

+[1] Tanenbaum,A.:”Computer Networks second edition”, Prentice Hall, 1989.
+ [2] Justin A. Boyan and Michael L. Littman:”[[Packet routing in dynamically changing networks: A reinforcement learning approach|Packet routing in dynamically changing networks A reinforcement learning approach]]”, Advances in Neural Information Processing Systems, vol.6, pp 671&#8211;678, 1993.
+[3] Shailesh Kumar and Risto Miikkulainen,”[[Dual Reinforcement Q-Routing: An On-line adaptive routing algorithm|Dual Reinforcement Q-Routing An On-line adaptive routing algorithm]]”, Intelligent Engineering Systems Through
Artificial Neural Networks (ANNIE-97, St. Louis, MO), vol.7, pp. 231-238, 1997.
+[4] Patrick Goetz, Shailesh Kumar and Risto Miikkulainen :”On-Line Adaptation of a Signal Predistorter though Dual Reinforcement Learning”, Proc. 13th Annual Conf. on Machine Learning, pp.175-181, 1996
+[5] Devika Subramanian, Peter Druschel and Johnny Chen : “[[Ants and reinforcement learning : A case study in routing in dynamic network|Ants and reinforcement learning A case study in routing in dynamic network]]”, In Proceedings of International Joint Conference on Artificial Intelligence (IJCAI-97), pp.832-839, 1997.
+[6] J.C.H Watkins and P.Dayan: ”Q-learning”, Machine Learning Vol.8, pp.279-292,1992.
+[7] Singo Kato and Hiroshi Matsuo: “A Theory of profit sharing in dynamic environment”, 6th Pacific Rim International Conference on Artificial Intelligence( PRICAI2000),Lecture Note in Artificial Intelligence
1886. pp.115-124 (2000)
+[8] Di Caro, G. and Dorigo, M. ”[[AntNet: Distributed Stigmergetic Control for Communications Networks|AntNet Distributed Stigmergetic Control for Communications Networks]]”, Journal of Artificial Intelligence Research, Vol. 9, pp.317-365 (1998)

@
