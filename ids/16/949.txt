Ant-Q: A Reinforcement Learning approach to
the traveling salesman problem
{{category Ant-Q}}

{{paper ant/ml95.pdf}}

Luca M. Gambardella
{{category Luca M. Gambardella}}
{{category L. M. Gambardella}}
{{category L. Gambardella}}

IDSIA
Corso Elvezia 36
6900 Lugano
Switzerland
luca@idsia.ch
http://www.idsia.ch

Marco Dorigo
{{category Marco Dorigo}}
{{category M. Dorigo}}

IRIDIA, Université Libre de Bruxelles
Avenue Franklin Roosevelt 50
CP 194/6
1050 Bruxelles, Belgium, EU
mdorigo@ulb.ac.be
http://iridia.ulb.ac.be/dorigo/dorigo.html

*Abstract
In this paper we introduce Ant-Q, a family of
algorithms which present many similarities
with Q-learning (Watkins, 1989), and which we
apply to the solution of symmetric and asymmetric
instances of the traveling salesman problem
(TSP). Ant-Q algorithms were inspired by
work on the ant system (AS), a distributed algorithm
for combinatorial optimization based on
the metaphor of ant colonies which was recently
proposed in (Dorigo, 1992; Dorigo, Maniezzo
and Colorni, 1996). We show that AS is a particular
instance of the Ant-Q family, and that
there are instances of this family which perform
better than AS. We experimentally investigate
the functioning of Ant-Q and we show that the
results obtained by Ant-Q on symmetric TSP's
are competitive with those obtained by other
heuristic approaches based on neural networks or
local search. Finally, we apply Ant-Q to some
difficult asymmetric TSP's obtaining very good
results: Ant-Q was able to find solutions of a
quality which usually can be found only by very
specialized algorithms.
{{category TSP}}
{{category ACO}}

* Introduction 抜粋

We recently realized that AS can be interpreted as
a particular kind of distributed reinforcement learning
(RL) technique. In this paper we propose Ant-Q, a
family of algorithms which strengthen the connection
between RL, in particular Q-learning, and AS. 

*References
Balas E., S. Ceria and G. Cornuéjols, 1993. A lift-andproject
cutting plane algorithm for mixed 0-1 programs,
Mathematical Programming 58, 295&#8211;324.
Colorni A., M. Dorigo and V. Maniezzo, 1991.
Distributed Optimization by Ant Colonies.
Proceedings of ECAL91 - European Conference on
Artificial Life, Paris, France, F.Varela and P.Bourgine
(Eds.), Elsevier Publishing, 134&#8211;142.
Colorni A., M. Dorigo and V. Maniezzo, 1992. An
Investigation of some Properties of an Ant
Algorithm. Proceedings of the Parallel Problem
Solving from Nature Conference (PPSN 92),
Brussels, Belgium, R.Männer and B.Manderick (Eds.),
Elsevier Publishing, 509&#8211;520.
Dorigo M., 1992. Optimization, Learning and Natural
Algorithms. Ph.D.Thesis, Politecnico di Milano,
Italy, EU. (In Italian.)
Dorigo M. and L.M. Gambardella, 1995. Ant-Q: A
Reinforcement Learning Approach to Combinatorial
Optimization. Tech. Rep. IRIDIA/95-01, Université
Libre de Bruxelles, Belgium.
Dorigo M., V.Maniezzo and A.Colorni, 1996. The Ant
System: Optimization by a colony of cooperating
agents. IEEE Transactions on Systems, Man, and
Cybernetics, 26, 2, in press.
Durbin R. and D. Willshaw, 1987. An analogue approach
to the travelling salesman problem using an elastic
net method. Nature, 326, 689-691.
Fischetti M. and P.Toth, 1992. An Additive Bounding
Procedure for the Asymmetric Travelling Salesman
Problem. Mathematical Programming, 53, 173&#8211;197.
Fischetti M. and P.Toth, 1994. A polyhedral approach
for the exact solution of hard ATSP instances.
Technical Report OR-94, DEIS, Università di
Bologna, Italy, April 1994.
Lin S., 1965. Computer solutions of the traveling
salesman problem. Bell Syst. Journal, 44, 2245&#8211;
2269.
Padberg M. and G. Rinaldi, 1990. Facet identification for
the symmetric traveling salesman problem.
Mathematical programming 47, 219&#8211;257.
Potvin J&#8211;Y., 1993. The traveling salesman problem: A
neural network Perpective. ORSA Journal of
Computing, 5, 4, 328&#8211;347.
Reinelt G., 1994. The traveling salesman: Computational
solutions for TSP applications. Springer-Verlag.
Siegel S. and N.J. Castellan, 1956. Nonparametric
statistics for the behavioral sciences. McGraw-Hill.
Watkins C.J.C.H., 1989. Learning with delayed rewards.
Ph. D. dissertation, Psychology Department,
University of Cambridge, England.
Whitley D., T. Starkweather and D. Fuquay, 1989.
Scheduling problems and travelling salesman: the genetic
edge recombination operator. Proceedings of the
Third International Conference on Genetic
Algorithms, Morgan Kaufmann, 133&#8211;140.
