A STUDY OF SOME PROPERTIES OF ANT-Q
{{category Ant-Q}}

{{paper ant/dorigo96study.pdf}}

TR/IRIDIA/1996-4

Université Libre de Bruxelles
Belgium

Marco Dorigo and Luca Maria Gambardella
{{category Marco Dorigo}}
{{category M. Dorigo}}
{{category Luca Maria Gambardella}}
{{category L. M. Gambardella}}
{{category L. Gambardella}}

IDSIA, Corso Elvezia 36, CH-6900 Lugano, Switzerland
dorigo@idsia.ch, luca@idsia.ch

*Abstract.

Ant-Q is an algorithm belonging to the class of ant colony based methods,
that is, of combinatorial optimization methods in which a set of simple agents, called
ants, cooperate to find good solutions to combinatorial optimization problems. The
main focus of this article is on the experimental study of the sensitivity of the Ant-Q
algorithm to its parameters and on the investigation of synergistic effects when using
more than a single ant. We conclude comparing Ant-Q with its ancestor Ant System,
and with other heuristic algorithms.
Published in the Proceedings of PPSN IV&#8211;Fourth International Conference on Parallel
Problem Solving From Nature, H.&#8211;M. Voigt, W. Ebeling, I. Rechenberg and H.&#8211;S.
Schwefel (Eds.), Springer-Verlag, Berlin, 656&#8211;665.
{{category ACO}}
{{category TSP}}
{{category 最適化問題}}

*1 Introduction
In this paper we study some properties of Ant-Q, a novel distributed approach to combinatorial
optimization based on reinforcement learning. Ant-Q (Gambardella and Dorigo,
1995) finds its ground in one of the authors previous work on the so-called Ant System
(Colorni, Dorigo and Maniezzo, 1991; 1992; Dorigo, 1992; Dorigo, Maniezzo and Colorni,
1996), and in the Q-learning algorithm (Watkins, 1989). Ant System (AS), which will not
be discussed here, is a distributed algorithm loosely based on the observation of ant
colonies behavior, hence its name. It has been applied to various combinatorial optimization
problems like the symmetric and asymmetric traveling salesman problems (TSP and
ATSP respectively), and the quadratic assignment problem (Maniezzo, Colorni and Dorigo,
1994). Ant-Q is an extension of AS, which is reinterpreted in the light of reinforcement
learning and in particular of Q-learning recent literature. This paper is devoted to a study
of some of Ant-Q characteristics, and to a comparison of Ant-Q with AS and other
heuristics, in which we show Ant-Q superiority. Ant-Q is different from Q-learning in that
while typical applications of Q-learning see one single agent exploring the state space, Ant-
Q uses a set of cooperating agents. These agents cooperate exchanging information in the
form of AQ-values (the analogous of Q-values in Q-learning). Last, Ant-Q agents have
some memory: this is necessary, as explained in Section 2, due to the different nature of our
application problems (combinatorial optimization) with respect to typical Q-learning applications.


*References

+Bersini H., C. Oury and M. Dorigo, 1995. Hybridization of genetic algorithms. Tech. Rep. No. IRIDIA/95-22, IRIDIA, Université Libre de Bruxelles, Belgium.
Colorni A., M. Dorigo and V. Maniezzo, 1991. Distributed Optimization by Ant Colonies.
+Proceedings of ECAL91 - European Conference on Artificial Life, Paris, France, F.Varela and P.Bourgine (Eds.), Elsevier Publishing, 134&#8211;142.
+Colorni A., M. Dorigo and V. Maniezzo, 1992. [[An Investigation of some Properties of an Ant Algorithm]]. Proceedings of the Parallel Problem Solving from Nature Conference (PPSN 92), Brussels, Belgium, R.Männer and B.Manderick (Eds.), Elsevier Publishing, 509&#8211;520.
+Dorigo M., 1992. [[Optimization, Learning and Natural Algorithms]]. Ph.D.Thesis, Politecnico di Milano, Italy. (In Italian.)
+Dorigo M., V.Maniezzo and A.Colorni, 1996. [[The Ant System: Optimization by a colony of cooperating agents|The Ant System Optimization by a colony of cooperating agents]]. IEEE Transactions on Systems, Man, and Cybernetics&#8211;Part B,
26, 2, 29&#8211;41.
+Eilon S., C.D.T. Watson-Gandy and N. Christofides, 1969. [[Distribution management: mathematical modeling and practical analysis|Distribution management mathematical modeling and practical analysis]]. Operational Research Quarterly, 20, 37&#8211;53.
+Fischetti M. and P.Toth, 1992. [[An Additive Bounding Procedure for the Asymmetric Travelling Salesman Problem]]. Mathematical Programming, 53, 173&#8211;197.
+Fischetti M. and P.Toth, 1994. A polyhedral approach for the exact solution of hard ATSP instances. Tech. Rep. OR-94, DEIS, Università di Bologna, Italy, April 1994.
+Fogel D., 1993. Applying evolutionary programming to selected traveling salesman
problems. Cybernetics and Systems: An International Journal, 24, 27&#8211;36.
+Gambardella L. and M. Dorigo, 1995. [[Ant-Q: A Reinforcement Learning approach to the traveling salesman problem|Ant-Q A Reinforcement Learning approach to the traveling salesman problem]]. Proceedings of ML-95, Twelfth International Conference on Machine Learning, Tahoe City, CA, A. Prieditis and S. Russell (Eds.), Morgan Kaufmann, 252&#8211;260.
+Lin F.&#8211;T., C.&#8211;Y. Kao and C.&#8211;C. Hsu, 1993. Applying the genetic approach to simulated annealing in solving some NP-hard problems. IEEE Transactions on Systems, Man, and Cybernetics, 23, 1752&#8211;1767.
+Watkins C.J.C.H., 1989. Learning with delayed rewards. Ph. D. dissertation, Psychology Department, University of Cambridge, England.
+Whitley D., T. Starkweather and D. Fuquay, 1989. Scheduling Problems and Traveling Salesman: the Genetic Edge Recombination Operator. Proc. of the Third International Conference on Genetic Algorithms, Morgan Kaufmann, 133&#8211;140.

