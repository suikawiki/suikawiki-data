An investigation of some properties
of an "Ant algorithm"

<http://scholar.google.com/scholar?q=cache:uHCiwPUHLskJ:dsp.jpl.nasa.gov/members/payman/swarm/colorni92-ppsn.pdf>

Alberto Colorni
Marco Dorigo
Vittorio Maniezzo
{{category Alberto Colorni}}
{{category A. Colorni}}
{{category Marco Dorigo}}
{{category M. Dorigo}}
{{category Vittorio Maniezzo}}
{{category V. Maniezzo}}

Dipartimento di Elettronica
PM-AI&R Project
PM-AI&R Project
Politecnico di Milano
Dipartimento di Elettronica
Dipartimento di Elettronica
20133 Milano, Italy
Politecnico di Milano
Politecnico di Milano
20133 Milano, Italy
20133 Milano, Italy
dorigo@ipmel2.elet.polimi.it
maniezzo@ipmel2.elet.polimi.it

!!!Abstract

We have used the metaphor of ant colonies to define "the Ant system", a class of distributed
algorithms for combinatorial optimization. To test the Ant system we used the travelling
salesman problem. In this paper we analyze some properties of Ant-cycle, the up to now best
performing of the ant algorithms we have tested. We report many results regarding its
performance when varying the values of control parameters and we compare it with some TSP
specialized algorithms.
{{category Ant System}}
{{category ACO}}
{{categoty TSP}}
{{category Ant-cycle}}

*1. Introduction

Most of the work done in the distributed systems research area is justified by the rapid
growth of importance of parallel computers. The interest of distributing an activity over several
interacting but not centrally controlled agents is however twofold and regards both the quality
of the solutions obtained and the speed of their obtainement. In fact, the underlying rationale
for parallelizing an algorithm or for distributing it on a set of communicating computers is the
hope to increase its speed of execution. This can be done only to a limited extent: at most, the
use of a parallel computer can cut down the computational time by a factor that is linear with the
number of processors.

The raw power of parallel hardware is best exploited by algorithms specifically designed for
distribution, where simple activities can be performed in parallel (thus assigned to different
processors) with rare local co-ordinating phases, which do not account for significant
computational load. In this case, superlinear speedups have been reported [5].
In this paper we are interested in this second property of distributed systems, with special
regard to the emergence of global properties from the interaction of many simple agents. The
computations carried out by these simple agents can effectively be executed on parallel
hardware, for instance by a transputer machine or by the simple processors of a massively
parallel computer such as the Connection Machine.

In our work we call ant each simple agent and the distributed system (called Ant system, see
[6]) is a set of ants cooperating in a common problem solving activity. A first result of our
research is that the interaction of these ants generates synergetic effects. In fact, the quality of
the solution obtained increases when the number of ants working on the problem increases
(until an upper limit is reached) more than the corresponding quality obtained with the same
number of non-communicating ants..

The problem we used to test our system is the well known Travelling Salesman Problem
(TSP) often used as a benchmark for new general purpouse heuristics [1], [14], [17]. In this
paper we are interested in the comparison of our heuristics with other ones, and not directly in
proposing &#8211; at least at this stage of our research &#8211; a more efficient approach to the solution of
TSP (which in fact has been solved optimally for problems of much higher order than those
presented here).

In this paper we study Ant-cycle, a particular instance of the algorithms belonging to the Ant
system class (other instances were proposed in [7]). Ant-cycle, as all the ant algorithms, is
composed by a set of simple agents, ants, that cooperate to find a minimal tour.

In Ant-cycle every ant changes the system shared memory using a quantity (called trail) that
is proportional to its global behavior. This makes Ant-cycle superior to other instances of ant
algorithms (like Ant-density and Ant-quantity presented in [7]) that use strictly local
information.

The properties of Ant-cycle that we repoert about are: the optimal parameters settings, how
many ants to use to solve a given problem and how many cycles are required to find an optimal
solution. Moreover, we compare Ant-cycle with some other specialized heuristics.

The paper is organized as follows: section 2 contains a brief description of the Ant system
and of the Ant-cycle algorithm as it is currently implemented, together with the definition of the
application problem (as the algorithm structure partially reflects the problem structure, we
introduce them together). Section 3 reports diffusely on experiments run using the algorithm
previously introduced. In section 4 we conclude discussing results obtained and some related
work. We also give some hints about further research directions.

*4. Conclusions

Results presented in the preceding sections suggest that the algorithm could be an effective
optimization tool. The Ant system uses many simple interacting agents and a fast search
algorithm based on positive feedback, without getting trapped in local minima; moreover
augmenting the number of agents has a synergetic effect on the system performance, until an
upper limit is reached.

A way to explain the effect of applying the algorithm to the TSP problem is to imagine to
have some kind of probabilistic superimposition of effects: each ant, if isolated (i.e., if α=0),
would move with a local, greedy rule. This greedy rule guarantees only locally optimal moves:
it doesn't work because that greedy local improvements very often lead to very bad final steps
(an ant is constrained to make a closed tour and therefore choices for the final steps are
constrained by early steps). So the tour followed by an ant ruled by a greedy policy is
composed by some parts that are very good and some others that are not. If we now consider
the effect of the simultaneous presence of many ants, then each one contributes to a part of the
trail distribution: good sets of paths will be followed by many ants and therefore they receive a
great amount of trail, which in turn will make the path even more attractive (thus giving rise to a
positive feedback &#8211; or autocatalytic &#8211; process - see also [10]); bad paths chosen only because
obliged by constraints satisfaction (the tabu list) will be chosen only by few ants and therefore
the trail over them remains low. When agents interact it looks like the greedy force can give the
right suggestions to the autocatalytic process and let it converge on very good, often optimal,
solutions very quickly, without getting stuck in local optima. Bad tours become highly
improbable, and the algorithm searches only in the neighbourhood of good solutions.

We have seen that the ants cooperate by exchanging a particular kind of information, the trail,
that is memorized in the problem structure. As no direct communication is necessary, and only
local information is used to take decisions, the algorithm is very well suited to parallelization.

We are currently designing the parallel version of Ant-cycle for a transputer architecture: we
intend to give a set of ants to each transputer and to merge, every n steps, the trail left by each
set of ants obtaining in this way a new trail matrix. We then redistribute this matrix to all the
nodes.

With respect to the generality of our approach, we believe that many combinatorial problems
can be faced by the Ant system. In order to apply the autocatalytic algorithm to another
combinatorial problem, we must find an appropriate representation for:
+1) the problem (to be represented as a graph searched by many simple agents),
+2) the autocatalytic process,
+3) the heuristic that allows a constructive definition of the solutions (the "greedy force"),
+4) the constraint satisfaction method (viz. the tabu list).

This has been done for two well known combinatorial optimization problems &#8211; Quadratic
Assignment (
QAP
) and Job-Shop Scheduling (
JSP
) &#8211; each time obtaining an adapted version of
the Ant system that could effectively handle the corresponding problem.
Related work can be classified in the following major areas:
+(i) studies of social animals behavior,
+(ii) research in "natural algorithms",
+(iii) stochastic optimization.

Research on behavior of social animals is to be considered as a source of inspiration and as a
useful metaphor to explain our ideas. In particular, the work done on foraging behavior of real
ants ([8], [9], [15]) has been our main source of inspiration. We believe that, especially if we
are interested to design inherently parallel algorithms, observation of natural systems can be an
invaluable source of inspiration. Neural networks [22], genetic algorithms [16], evolution
strategies [20], immune networks [2], [3], simulated annealing [18] are only some of the
proposed models with a "natural flavour". Main characteristics, at least partially shared by
members of this class of algorithms, are the use of a natural metaphor, the inherent parallelism,
the stochastic nature and adaptivity, the use of positive feedback, the capacity to learn (i.e., to
improve performance on the basis of past experience). All this work in "natural optimization"
can be inserted in the more general research area of stochastic optimization, in which the quest
for optimality is traded for computational efficiency.

*References

1 .
Aarts, E. and Korst, J. Simulated Annealing and Boltzmann Machines, John Wiley
(1989).
2 .
Bersini, H. Hints for Adaptive Problem Solving Gleaned from Immune Networks. In
Proceedings First International Conference on Parallel Problem Solving from Nature
(PPSN I), Schwefel, H.P. and Männer, R., Springer-Verlag, 1990.
3 .
Bersini, H. and Varela, F.J. The Immune Recruitment Mechanism: a Selective
Evolutionary Strategy. In Proceedings of the Fourth International Conference on Genetic
Algorithms, Morgan Kaufmann, UCSD - San Diego - CA, July 1991.
4 .
Boyd, S.C., Pulleyblank, W.R., and Cornuejols, G., Travel, Software Package -
Carleton University, January 1989.
5 .
Clearwater, S.H., Hogg, T., and Huberman, B.A. Cooperative Problem Solving. Tech.
Rept. Xerox Palo Alto Research Center, 1992.
6 .
Colorni, A., Dorigo, M., and Maniezzo, V. Positive Feedback as a Search Strategy.
Tech. Rept. 91-16 Politecnico di Milano - Department of Electronics, Milano - Italy,
November, 1991.
7 .
Colorni, A., Dorigo, M., and Maniezzo, V. Distributed Optimization by Ant Colonies.
In Proceedings First European Conference on Artificial Life, MIT Press/Bradford Books,
Paris, December 1991.
8 .
Denebourg, J.L., Pasteels, J.M., and Verhaeghe, J.C. Probabilistic Behaviour in Ants: a
Strategy of Errors?. Journal of Theoretical Biology 105(1983).
9 .
Denebourg, J.L. and Goss, S. Collective Patterns and Decision-making. Ethology,
Ecology & Evolution 1(1989).
10. Dorigo, M. Optimization, Learning and Natural Algorithms, Ph.D. dissertation,
Politecnico di Milano - PM-AI & R Project, Milano - Italy, February 1992.
11. Eilon, S., Watson-Gandy, T.H., and Christofides, N. Distribution Management:
mathematical modeling and practical analysis. Operational Research Quarterly 20(1969).
12. Glover, F. Tabu Search ― Part I. ORSA Journal on Computing 1, 3 (1989).
13. Glover, F. Tabu Search ― Part II. ORSA Journal on Computing 2, 1 (1990).
14. Goldberg, D.E. and Lingle, R. Alleles, Loci, and the Traveling Salesman Problem. In
Proceedings First International Conference on Genetic Algorithms, Morgan Kaufmann,
Carnegie-Mellon University - Pittsburg - PA, July 1985.
15. Goss, S., Beckers, R., Denebourg, J.L., Aron, S., and Pasteels, J.M. Behavioural
Mechanisms of Food Selection, Springer-Verlag: Berlin, Vol. G20, NATO ASI (1990).
16. Holland, J.H. Adaptation in Natural and Artificial Systems, Ann Arbor: The University
of Michigan Press (1975).
17. Hopfield, J.J. and Tank, D.W. Neura Computation of Decisions in Optimization
Problems. Biological Cybernetics 52(1985).
18. Kirkpatrick, S., Gelatt, C.D., and Vecchi, M.P. Optimization by Simulated Annealing.
Science 220(1983).
19. Lin, S. and Kernighan, B.W. An Effective Heuristic Algorithm for the TSP. Operations
Research 21(1973).
20. Rechenberg, I. Evolutionsstrategie, Fromman-Holzbog, Stuttgart, Germany (1973).
21. Reinelt, G., TSPLIB 1.0, Institut für Mathematik, Universität Augsburg, Germany,
1990.
22. Rumelhart, D.E. and McLelland, J.L. Parallel Distributed Processing: Explorations in the
Microstructure of Cogniton, MIT Press (1986).
23. Whitley, D., Starkweather, T., and Fuquay, D. Scheduling Problems and Travelling
Salesmen: the Genetic Edge Recombination Operator. In Proceedings Third International
Conference on Genetic Algorithms, Morgan Kaufmann, George Mason University,
1989.

